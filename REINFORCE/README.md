# REINFORCE 策略梯度算法




## 实验

1： 完全没学习到。


1to2的消融实验：
想法1：源代码层数较多，隐藏层较小导致不好训练。 =》调整参数。
实验结果：提升很少。 发现实验loss较大，这是因为reward没有进行归一化造成的，log_prob数值正常。

想法2：加入reward归一化。
实验结果：提升很少。 loss和reward平稳，log_prob数值分布范围为-0.4~-0.9这样，几乎不变，说明log_prob不收敛。
怀疑是梯度问题。